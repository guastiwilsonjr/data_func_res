{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Artigo ICCSA - 2022.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTEDys+BUPyBtnsYRtegq2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guastiwilsonjr/data_func_res/blob/main/Artigo_ICCSA_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação da bibliotecas necessárias ao funcionamento do algoritmo"
      ],
      "metadata": {
        "id": "_bZHNaGkLJs4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ7smB1bKrXz",
        "outputId": "549b6df9-c0b8-4ad3-f241-81b277356dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.23.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install numpy\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atualizar funções para a versão mais recente do Tensorflow\n",
        "\n",
        "Referências de recursos da biblioteca\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense"
      ],
      "metadata": {
        "id": "EodKaaNTRbM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algoritmo básico - resolução de uma EDO\n"
      ],
      "metadata": {
        "id": "6ciIw2zbMtLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# import tensorflow.compat.v1 as tf\n",
        "\n",
        "from matplotlib import rc\n",
        "\n",
        "from tempfile import TemporaryFile\n",
        "\n",
        "# # FUNCIONALIDADE QUE PERMITE A COMPATIBILIDADE COM A VERSÃO 1.5 DO TENSORFLOW\n",
        "# tf.disable_v2_behavior()\n",
        "\n",
        "\n",
        "# Limpa a pilha de grafos padrão e redefine o grafo padrão global\n",
        "# tf.reset_default_graph()\n",
        "\n",
        "#Define os valores aleatórios no nível do grafo para o grafo padrão\n",
        "# tf.set_random_seed(1000)\n",
        "# ERRADO\n",
        "\n",
        "#PROBLEMA A SER RESOLVIDO\n",
        "#EQUACOES DIFERENCIAIS ORDINARIAS DE PRIMEIRA ORDEM (PROBLEMA DE VALOR INICIAL - PVI)\n",
        "#====================================================================================\n",
        "#FORMA DO PVI\n",
        "#  du(t)/dt + p(t)u(t) = q(t),   t \\in [t_0, t_f] \n",
        "#               u(t_0) = u_0\n",
        "#\n",
        "#Esse PVI pode ser escrito da forma du(t)/dt = f(t,u)\n",
        "#onde f(t,u) = q(t) - p(t)u(t)\n",
        "#Nesse problema, t_0 = 0, t_f =1, u_0 = 1 e p e q sao descritas pelas funcoes p e q\n",
        "#===================================================================================\n",
        "\n",
        "\n",
        "#===================================================================================\n",
        "#FUNCAO QUE DESCREVE A FUNCAO p(t)\n",
        "def p(x):\n",
        "    '''\n",
        "        Left part of initial equation\n",
        "    '''\n",
        "    return x + (1. + 3.*x**2) / (1. + x + x**3)\n",
        "#===================================================================================\n",
        "\n",
        "#===================================================================================\n",
        "#FUNCAO QUE DESCREVE A FUNCAO q(t)\n",
        "def q(x):\n",
        "    '''\n",
        "        Right part of initial equation\n",
        "    '''\n",
        "    return x**3 + 2.*x + x**2 * ((1. + 3.*x**2) / (1. + x + x**3))\n",
        "#===================================================================================\n",
        "\n",
        "#===================================================================================\n",
        "#SOLUCAO EXATA\n",
        "def g_analytic(x):\n",
        "    # return x*(1-x)*np.exp(x)\n",
        "    return ((np.exp((-x**2)/2.)) / (1. + x + x**3)) + x**2\n",
        "#===================================================================================\n",
        "\n",
        "Nx = 10\n",
        "\n",
        "# RETORNAM NÚMEROS IGUALMENTE ESPAÇADOS DENTRO DO INTERVALO ESPECIFICADO [NX]\n",
        "x = np.linspace(0,1, Nx)\n",
        "\n",
        "\n",
        "# CONVERTER OBJETO PYTHON PARA OBJETOS DO TIPO TENSOR\n",
        "x_tf = tf.convert_to_tensor(x.reshape(-1,1),dtype=tf.float64)\n",
        "g1 = tf.constant(1.,dtype=tf.float64)\n",
        "g2 = tf.constant(2.,dtype=tf.float64)\n",
        "g3 = tf.constant(3.,dtype=tf.float64)\n",
        "\n",
        "\n",
        "# NÚMERO DE ITERAÇÕES\n",
        "num_iter = 10000\n",
        "\n",
        "# VARIÁVEL PARA O CÁLCULO DO DECAIMENTO DO FUNCIONAL RESÍDUO\n",
        "vector_functional_dominio = np.zeros(num_iter)\n",
        "vector_functional = np.zeros(num_iter)\n",
        "\n",
        "# NÚMERO DE NEURÔNIOS EM CADA CAMADA, SÃO DUAS CAMADAS\n",
        "num_hidden_neurons = [10,10]\n",
        "\n",
        "# NÚMERO DE CAMADAS É DEFINIDO PELA QUANTIDADE DE ELEMENTOS NA LISTA\n",
        "num_hidden_layers = np.size(num_hidden_neurons)\n",
        "\n",
        "\n",
        "# CONSTRUÇÃO DA REDE\n",
        "# AGRUPAMENTO DE CADA PASSO NA CONSTRUÇÃO DA REDE NEURAL\n",
        "with tf.name_scope('dnn'):\n",
        "\n",
        "    # CAMADA DE ENTRADA\n",
        "    previous_layer = x_tf\n",
        "\n",
        "    # CAMADAS ESCONDIDAS\n",
        "    for l in range(num_hidden_layers):\n",
        "        # A VERSÃO MAIS ATUAL DA FUNÇÃO UTILIZA A INTERFACE DO KERAS \n",
        "        #current_layer = tf2.keras.layers.Dense()\n",
        "\n",
        "        # tf.layers.dense --> FUNÇÃO DESCONTINUADA\n",
        "        # DENSE REPRESENTA A CAMADA: SAÍDA = FUNÇÃO_ATIVAÇÃO (ENTRADA * KERNEL + BIAS), ONDE\n",
        "        # KERNEL É A MATRIZ DE PESOS E O BIAS É UM VETOR CRIADO PELA CAMADA\n",
        "        #(ENTRADA, NÚMERO DE DIMENSÃO DA SAÍDA, NOME, FUNÇÃO DE ATIVAÇÃO, INICIALIZAÇÃO DOS PESOS DA MATRIZ)\n",
        "        # current_layer = tf.layers.dense(previous_layer, num_hidden_neurons[l], name='hidden%d'%(l+1), activation=tf.nn.sigmoid)\n",
        "        current_layer = tf.keras.layers.Dense(previous_layer, num_hidden_neurons[l], name='hidden%d'%(l+1), activation=tf.nn.relu,kernel_initializer='glorot_uniform')\n",
        "        previous_layer = current_layer\n",
        "\n",
        "    # CAMADA DE SAÍDA\n",
        "    dnn_output = tf.layers.dense(previous_layer, 1, name='output')\n",
        "\n",
        "\n",
        "# DEFINIÇÃO DA FUNÇÃO TRIAL E DA SEÇÃO CUSTO\n",
        "with tf.name_scope('custo'):\n",
        "    # FUNÇÃO TRIAL\n",
        "    # g_trial = x_tf * dnn_output\n",
        "    g_trial = 1.  + x_tf * dnn_output\n",
        "    # g_trial = x_tf*(x_tf-1)*dnn_output\n",
        "    # psy_t = 1. + xi * net_out\n",
        "\n",
        "    # DERIVADA DA FUNÇÃO TRIAL\n",
        "    d_g_trial = tf.gradients(g_trial,x_tf)\n",
        "    \n",
        "    # DERIVADA SEGUNDA DA FUNÇÃO TRIAL\n",
        "    # d2_g_trial = tf.gradients(d_g_trial,x_tf)\n",
        "\n",
        "    # right_side = (3*x_tf + x_tf**2)*tf.exp(x_tf)\n",
        "    # right_side = x_tf**3 + 2*x_tf + x_tf**2 * ((1 + 3*x_tf**2) / (1 + x_tf + x_tf**3))\n",
        "    right_side = q(x_tf) - g_trial*p(x_tf)\n",
        "    # right_side = q(g_trial) - x_tf*p(g_trial)\n",
        "\n",
        "    err = tf.square( d_g_trial[0] - right_side)\n",
        "    custo = tf.reduce_sum(err, name = 'custo')\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ESCOLHA DO MÉTODO PARA MINIMIZAR A FUNÇÃO CUSTO\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# TAXA DE APRENDIZAGEM\n",
        "learning_rate = 0.001\n",
        "with tf.name_scope('treinamento'):\n",
        "    # MÉTODO DE MINIMIZAÇÃO - GRADIENT DESCENT\n",
        "    # optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    \n",
        "    # MÉTODO DE MINIMIZAÇÃO - ADAM\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "    # MÉTODO DE MINIMIZAÇÃO - ADADELTA\n",
        "    # optimizer = tf.train.AdadeltaOptimizer(learning_rate)\n",
        "\n",
        "    # MÉTODO DE MINIMIZAÇÃO - ADADELTA\n",
        "    # optimizer = tf.train.AdadeltaOptimizer(learning_rate)\n",
        "\n",
        "\n",
        "    # optimizer = tfp.optimizer.StochasticGradientLangevinDynamics(learning_rate)\n",
        "    # optimizer = tfp.optimizer.bfgs_minimize(quadratic_loss_and_gradient, initial_position=start, \n",
        "    #     tolerance=1e-8)\n",
        "\n",
        "    traning_op = optimizer.minimize(custo)\n",
        "\n",
        "g_dnn_tf = None\n",
        "\n",
        "\n",
        "# DEFINE O NÓ QUE INICIALIZA TODOS OS OUTROS NÓS DO GRAFO - NO CASO, AS CAMADAS \n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# print(\"valor de init:\", init)\n",
        "\n",
        "\n",
        "\n",
        "# ETAPA DE CONSTRUÇÃO DO GRAFO - REDE\n",
        "with tf.Session() as sess:\n",
        "   \n",
        "    # INICIALIZA TODA A REDE\n",
        "    # EM TODAS AS ETAPAS SERÃO CHAMADAS AS SESSÕES CONSTRUIDAS ACIMA\n",
        "    init.run()\n",
        "\n",
        "    \n",
        "    # AVALIAR O CUSTO INICIAL - CHAMA A SESSÃO CUSTO\n",
        "    # print('Custo inicial: %g'%custo.eval())\n",
        "\n",
        "\n",
        "    # INICIO DO TREINAMENTO DA REDE - CHAMA A SESSÃO TREINAMENTO\n",
        "    for i in range(num_iter):\n",
        "        sess.run(traning_op)\n",
        "        vector_functional_dominio[i] = i;\n",
        "        vector_functional[i] = custo.eval()\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "    # CÁLCULO DO VALOR MÍNIMO DO FUNCIONAL\n",
        "    min_Jr = np.min(err.eval())\n",
        "    \n",
        "\n",
        "    # ARMAZENAMENTO DO RESULTADO FINAL\n",
        "    # EVAL -> EXECUTA/TRANSFORMA O CONTEÚDO COMO/EM UMA EXPRESSÃO PYTHON\n",
        "    g_dnn_tf = g_trial.eval()\n",
        "\n",
        "    \n",
        "    # # FAZ A IMPRESSÃO DO RESULTADO FINAL DO GRAPO\n",
        "    # writer = tf.summary.FileWriter(\"./output\", sess.graph)\n",
        "    # writer.close()\n",
        "\n",
        "g_analytical = g_analytic(x)\n",
        "\n",
        "diff_tf = g_dnn_tf - g_analytical.reshape(-1,1)\n",
        "#=============================================================================\n",
        "#                   RUNGE KUTTA DE 2ª ORDEM\n",
        "#=============================================================================\n",
        "\n",
        "def feval(funcName, *args):\n",
        "    return eval(funcName)(*args)\n",
        "\n",
        "\n",
        "def RK2B(func, yinit, x_range, h):\n",
        "    m = len(yinit)\n",
        "    n = int((x_range[-1] - x_range[0])/h)\n",
        "    \n",
        "    x = x_range[0]\n",
        "    y = yinit\n",
        "    \n",
        "    # Containers for solutions\n",
        "    xsol = np.empty(0)\n",
        "    xsol = np.append(xsol, x)\n",
        "\n",
        "    ysol = np.empty(0)\n",
        "    ysol = np.append(ysol, y)\n",
        "\n",
        "    for i in range(n):\n",
        "        k1 = feval(func, x, y)\n",
        "\n",
        "        ypredictor = y + k1 * (h/2)\n",
        "\n",
        "        k2 = feval(func, x+h/2, ypredictor)\n",
        "\n",
        "        for j in range(m):\n",
        "            y[j] = y[j] + h*k2[j]\n",
        "\n",
        "        x = x + h\n",
        "        xsol = np.append(xsol, x)\n",
        "\n",
        "        for r in range(len(y)):\n",
        "            ysol = np.append(ysol, y[r])  \n",
        "\n",
        "    return [xsol, ysol]\n",
        "\n",
        "\n",
        "def myFunc(x, y):\n",
        "    dy = np.zeros((len(y)))\n",
        "    # dy[0] = np.exp(-2 * x) - 2 * y[0]\n",
        "    # dy[0] = x / (2*x**2+1)**0.5\n",
        "    dy[0] = q(x) - y[0] * p(x)\n",
        "    return dy\n",
        "\n",
        "# -----------------------\n",
        "h = 0.1\n",
        "# x = np.array([0, 1])\n",
        "\n",
        "# nx = 20\n",
        "\n",
        "x = np.linspace(0, 1, Nx)\n",
        "\n",
        "# mudança do valor inicial\n",
        "# yinit = np.array([1.0/10])\n",
        "yinit = np.array([1.0])\n",
        "\n",
        "\n",
        "\n",
        "# print('Resultado de RK2', [ts, ys])\n",
        "\n",
        "#=====METODO DE DIFERENCAS FINITAS EULER EXPLICITO ==================\n",
        "#Inicialização com os parâmetros iniciais\n",
        "#fd = finite difference\n",
        "y_space = g_analytic(x)\n",
        "dx = 1. / (Nx-1)\n",
        "psy_fd = np.zeros_like(y_space) #np.zeros_like retorna um vetor nulo\n",
        "psy_fd[0] = 1. # Condição inicial\n",
        "\n",
        "[ts, ys] = RK2B('myFunc', yinit, x, dx)\n",
        "\n",
        "for i in range(1, len(x)):\n",
        "    psy_fd[i] = psy_fd[i-1] + q(x[i]) * dx - psy_fd[i-1] * p(x[i]) * dx\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# IMPORTANTE  - CÁLCULO DAS MÉTRICAS\n",
        "# CÁLCULO DA NORMA DO INFINITO\n",
        "# print('\\nNorma do Infinito: %g'%np.max(np.abs(diff_tf)))\n",
        "print('\\nNorma do Infinito: {:.3e}'.format(np.max(np.abs(diff_tf))))\n",
        "\n",
        "\n",
        "# # # CÁLCULO DA NORMA L2\n",
        "norma_l2 = np.sqrt(np.cumsum(np.power(diff_tf,2))[Nx-1])\n",
        "# # print('\\nNorma L2: {:.7f}'.format(norma_l2))\n",
        "print('\\nNorma L2: {:.3e}'.format(norma_l2))\n",
        "\n",
        "# # # IMPRESSÃO DO FUNCIONAL\n",
        "# # print('\\nValor mínimo do funcional Jr: {:.7f}'.format(min_Jr))\n",
        "print('\\nValor mínimo do funcional Jr: {:.3e}'.format(min_Jr))\n",
        "\n",
        "# =========================================================\n",
        "#\n",
        "# COMPARAÇÃO ENTRE OS MÉTODOS RK2 ORDEM E DIFERENÇAS FINITAS\n",
        "#\n",
        "# =========================================================\n",
        "# plt.figure()\n",
        "# plt.plot(x, g_analytical, linestyle='solid',color='blue', marker=\"x\", lw=2, label='Solução exata')\n",
        "# plt.ylabel(r'Microstrain [$\\mu \\epsilon$]')\n",
        "# plt.plot(ts, ys, linestyle='solid',color='green', marker=\"^\", label='Runge-Kutta 2ª ordem')\n",
        "# plt.plot(x, g_dnn_tf, linestyle='solid', color='red', marker=\"s\", label='Redes Neurais')\n",
        "# plt.plot(x, psy_fd, linestyle='solid', color='black', marker=\"o\", label='Euler explícito')\n",
        "# plt.grid(True)\n",
        "# plt.title('du(x)/dx + p(x) u(x) = q(x)')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "#================================================================================================================================\n",
        "#                                                    ERROS - NORMA INFINITO\n",
        "#================================================================================================================================\n",
        "\n",
        "def norma_infinito(u, v, n):\n",
        "    maior = abs(u[0]-v[0])\n",
        "    for i in range(n):\n",
        "        valor = abs(u[i]-v[i])\n",
        "        if (valor > maior):\n",
        "            maior = valor\n",
        "    return maior\n",
        "\n",
        "# print('Error - infinity norm - forward Euler method = ','%.3e' % norma_infinito(g_analytical, psy_fd, Nx))\n",
        "# print('Error - infinity norm - RK2 method = ','%.3e' % norma_infinito(g_analytical, ys, Nx))\n",
        "# print('Error - infinity norm - ANN method = ','%.3e' % norma_infinito(g_analytical, g_dnn_tf, Nx))\n",
        "\n",
        "\n",
        "# print('\\nNorma do Infinito: %g'%np.max(np.abs(diff_tf)))\n",
        "\n",
        "# # Plot the result\n",
        "# plt.figure()\n",
        "\n",
        "# # plt.title('du(t)/dt + p(t) u(t) = q(t)')\n",
        "\n",
        "# plt.plot(x, g_dnn_tf, linestyle='solid', color='red', marker=\"s\", label='Solução via Redes Neurais')\n",
        "# plt.plot(x, g_analytical, linestyle='solid', color='blue', marker=\"x\", label='Solução exata')\n",
        "# plt.xlabel('t')\n",
        "# plt.ylabel('y')\n",
        "# plt.grid(True)\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# plt.yscale('log',basey=2) \n",
        "\n",
        "# outfile = TemporaryFile()\n",
        "# np.save(outfile, vector_functional)\n",
        "\n",
        "# _ = outfile.seek(0) # Apenas para simular a abertura e fechamento do arquivo\n",
        "# teste = np.load(outfile)\n",
        "# print(teste)\n",
        "\n",
        "\n",
        "# with open('teste/relu.npy', 'wb') as f:\n",
        "#     np.save(f, vector_functional)\n",
        "# with open('teste/relu.npy', 'rb') as f:\n",
        "#     a = np.load(f)\n",
        "\n",
        "# print(a)\n",
        "print('dominio')\n",
        "print(vector_functional_dominio)\n",
        "\n",
        "# SALVAR OS PONTOS DO DOMÍNIO\n",
        "# with open('vector_functional_dominio.npy', 'wb') as g:\n",
        "#     np.save(g, vector_functional_dominio)\n",
        "# with open('vector_functional_dominio.npy', 'rb') as g:\n",
        "#     b= np.load(g) \n",
        "# print('dominio_salvo')\n",
        "# print(b)\n",
        "# DEACAIMENTO DO FUNCIONAL RESÍDUO\n",
        "plt.plot(b, vector_functional, color='blue', label='Funcional Resíduo')\n",
        "plt.rc('text', usetex=True)\n",
        "plt.xlabel('Nº iterações')\n",
        "plt.ylabel('$J_{R}$')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.semilogy()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "RcN52-mmMr6j",
        "outputId": "9e7aa21e-9ad2-4196-93ac-5e80e2522d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-660447fb5250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m#(ENTRADA, NÚMERO DE DIMENSÃO DA SAÍDA, NOME, FUNÇÃO DE ATIVAÇÃO, INICIALIZAÇÃO DOS PESOS DA MATRIZ)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# current_layer = tf.layers.dense(previous_layer, num_hidden_neurons[l], name='hidden%d'%(l+1), activation=tf.nn.sigmoid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mcurrent_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_neurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hidden%d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mprevious_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'activation'"
          ]
        }
      ]
    }
  ]
}